{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5d1c81",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "**Goals:**\n",
    "- Understand Text Feature Extraction.\n",
    "- Familiarize with `scikit-learn` and `python` to perform text classification on real datasets.\n",
    "\n",
    "The machine learning technique that will be utilized here is a supervised learning.\n",
    "\n",
    "Most classic machine learning algorithms can't take in raw test. Insead it is important to perform a feature extraction from the raw text in order to pass numerical features to the machine learning algorithm. For example, we could count the occurence of each word to map text to number. Or use Counter Vectorization along with Ter-Frequency and Inverse Document Frequency.\n",
    "\n",
    "An alternative to `CountVectorizer` is `TfidfVectorizer`. It also created document term matrix from the text. However, instead of filling the DTM with token counts it calculated term frequency-inverse document frequency value for each word (`TF-IDF`).\n",
    "\n",
    "In this case term frequency $tf(t,d)$ is the raw count of a term in a document, i.e. the number of times that term $t$ occurs in the document $d$. However, Term Frequency alone isn't enough for thorough feautre analysis of the text. Let's imagine very common terms like \"a\" or \"the\". Because the term \"the\" is so common, therm frequency will tend to incorrectly emphasize document which happen to use the word \"the\" more frequently, without giving enough weight to the more meaningul terms such as \"red\", \"dog\", \"weather\" etc.\n",
    "\n",
    "An inverse document frequency factor is incorporated which diminishes the weight of terms that occur very frequently in the document set and increases the weight of terms that occur rarely. It's logarithmically scaled inverse fraction of the documents that contain the word (obtained by dividing the total number of documents by the number of documents containing the term, and then taking the logarithm of that quotient).\n",
    "\n",
    "<br></br>\n",
    "<center>$tfidf(t,d,D) = tf(t,d) \\cdot idf(t,D)$</center>\n",
    "\n",
    "<br></br>\n",
    "<center>$idf(t, D) = \\log\\left(\\frac{N}{\\{d \\in D : t \\in d\\}}\\right)$</center>\n",
    "\n",
    "TF-IDF allows to understand the context of words across an entire corpus of documents, instead of just its relative importance in a single document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01110016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f1157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('smsspamcollection.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9baef399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7a0df93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d6ac7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "277b7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f540f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1861291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be4190c",
   "metadata": {},
   "source": [
    "## Count vectorization\n",
    "\n",
    "After we did the split it is time to perform count vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dfa337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488b9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4a7172",
   "metadata": {},
   "source": [
    "There are 2 ways of transforming raw text into vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400df10d",
   "metadata": {},
   "source": [
    "Fit the vectorizer to the data (build the vocab, count the number of words)\n",
    "\n",
    "`count_vect.fit(X_train)`\n",
    "\n",
    "`X_train_counts = count_vect.transfomr(X_train)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2204e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the original text message into vector\n",
    "X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d343cc37",
   "metadata": {},
   "source": [
    "We cannot view the `X_train_counts` because it is a huge sparse matrix. The `scikit-learn` compresses that into `Compressed Sparse Row format`. It looks like as if there a row with multiple zeroes so it is a lot better to count the number of zeroes instead of keeping them in the place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a44d0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3733x7082 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 49992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e1ba0",
   "metadata": {},
   "source": [
    "So, across 3733 messages there vere 7082 unique words as we can see from the output from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70d4b205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9135b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 7082)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f7fccc",
   "metadata": {},
   "source": [
    "## TF-IDF Tranformation\n",
    "\n",
    "Let's transofrm the counts into frequencies with `TF-IDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e1d2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab013dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce26139",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108ee3a",
   "metadata": {},
   "source": [
    "How we can see that it has the same shape but it is no longer counts. Instead, we've taken in the term frequency and multiply it by inverse document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "786a8578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 7082)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3bfe46",
   "metadata": {},
   "source": [
    "Since it is popular to do count vectorization and then TF-IDF tranfsomration, the option of TF-IDF Vectorizer is avaliable. And it does the same thing in 1 step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abd0052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be5eb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2074801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acbe282",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Let's train `SVM` classifier on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c9a461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a10e9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a115b922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc30ac7",
   "metadata": {},
   "source": [
    "## Pipeline creation\n",
    "\n",
    "Now our training set has been vectorized into a full vocabulary. In order to perform an analysis on the test set we have to repeat all the same procedures. `Scikit-learn` provide a pipeline class that essentialy behaves like a compound classifier. It can perform both vectorization. So in order not to repeat whole process once again let's use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4748d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f45f44",
   "metadata": {},
   "source": [
    "The pipeline object will take a list of tuples. Each tuble is going to have a string name that you decide on what to call this step in the pipeline. So `text-clf` will be able to perform all these steps in a single call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e82c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06b61730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43b93692",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7a2d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec5e8a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1586    7]\n",
      " [  12  234]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7b02bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1593\n",
      "        spam       0.97      0.95      0.96       246\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1839\n",
      "   macro avg       0.98      0.97      0.98      1839\n",
      "weighted avg       0.99      0.99      0.99      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67c02bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22e9b5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989668297988037"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba44c958",
   "metadata": {},
   "source": [
    "We can also predict on the new text message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7b949bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict(['Hi how are you doing today?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe71827b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"Congratulations! You've been selected as a winner. TEXT WON to 4255 congratulations free entry to contest.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13906e96",
   "metadata": {},
   "source": [
    "___\n",
    "# Movie Review project\n",
    "\n",
    "In this project we will use movie dataset in order to identify whether the review is positive or negative. We're going to predict just based of the test if that movie review is positive or negative on the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db9bae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab2d526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('moviereviews.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23dae024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daa9521e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb44b1d3",
   "metadata": {},
   "source": [
    "We can take a look at what the reviews like inside the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37c708d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how do films like mouse hunt get into theatres ? \\r\\nisn\\'t there a law or something ? \\r\\nthis diabolical load of claptrap from steven speilberg\\'s dreamworks studio is hollywood family fare at its deadly worst . \\r\\nmouse hunt takes the bare threads of a plot and tries to prop it up with overacting and flat-out stupid slapstick that makes comedies like jingle all the way look decent by comparison . \\r\\nwriter adam rifkin and director gore verbinski are the names chiefly responsible for this swill . \\r\\nthe plot , for what its worth , concerns two brothers ( nathan lane and an appalling lee evens ) who inherit a poorly run string factory and a seemingly worthless house from their eccentric father . \\r\\ndeciding to check out the long-abandoned house , they soon learn that it\\'s worth a fortune and set about selling it in auction to the highest bidder . \\r\\nbut battling them at every turn is a very smart mouse , happy with his run-down little abode and wanting it to stay that way . \\r\\nthe story alternates between unfunny scenes of the brothers bickering over what to do with their inheritance and endless action sequences as the two take on their increasingly determined furry foe . \\r\\nwhatever promise the film starts with soon deteriorates into boring dialogue , terrible overacting , and increasingly uninspired slapstick that becomes all sound and fury , signifying nothing . \\r\\nthe script becomes so unspeakably bad that the best line poor lee evens can utter after another run in with the rodent is : \" i hate that mouse \" . \\r\\noh cringe ! \\r\\nthis is home alone all over again , and ten times worse . \\r\\none touching scene early on is worth mentioning . \\r\\nwe follow the mouse through a maze of walls and pipes until he arrives at his makeshift abode somewhere in a wall . \\r\\nhe jumps into a tiny bed , pulls up a makeshift sheet and snuggles up to sleep , seemingly happy and just wanting to be left alone . \\r\\nit\\'s a magical little moment in an otherwise soulless film . \\r\\na message to speilberg : if you want dreamworks to be associated with some kind of artistic credibility , then either give all concerned in mouse hunt a swift kick up the arse or hire yourself some decent writers and directors . \\r\\nthis kind of rubbish will just not do at all . \\r\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative review\n",
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f568ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this has been an extraordinary year for australian films . \r\n",
      " \" shine \" has just scooped the pool at the australian film institute awards , picking up best film , best actor , best director etc . to that we can add the gritty \" life \" ( the anguish , courage and friendship of a group of male prisoners in the hiv-positive section of a jail ) and \" love and other catastrophes \" ( a low budget gem about straight and gay love on and near a university campus ) . \r\n",
      "i can't recall a year in which such a rich and varied celluloid library was unleashed from australia . \r\n",
      " \" shine \" was one bookend . \r\n",
      "stand by for the other one : \" dead heart \" . \r\n",
      ">from the opening credits the theme of division is established . \r\n",
      "the cast credits have clear and distinct lines separating their first and last names . \r\n",
      "bryan | brown . \r\n",
      "in a desert settlement , hundreds of kilometres from the nearest town , there is an uneasy calm between the local aboriginals and the handful of white settlers who live nearby . \r\n",
      "the local police officer has the task of enforcing \" white man's justice \" to the aboriginals . \r\n",
      "these are people with a proud 40 , 000 year heritage behind them . \r\n",
      "naturally , this includes their own system of justice ; key to which is \" payback \" . \r\n",
      "an eye for an eye . \r\n",
      "revenge . \r\n",
      "usually extracted by the spearing through of the recipient's thigh . \r\n",
      "brown , as the officer , manages quite well to keep the balance . \r\n",
      "he admits that he has to 'bend the rules' a bit , including actively encouraging at least one brutal \" payback \" . \r\n",
      " ( be warned that this scene , near the start , is not for the squeamish ) . \r\n",
      "the local priest - an aboriginal , but in the \" white fellas \" church - has a foot on either side of the line . \r\n",
      "he is , figuratively and literally , in both camps . \r\n",
      "ernie dingo brings a great deal of understanding to this role as the man in the middle . \r\n",
      "he is part churchman and part politician . \r\n",
      "however the tension , like the heat , flies and dust , is always there . \r\n",
      "whilst her husband - the local teacher - is in church , white lady kate ( milliken ) and her aborginal friend tony , ( pedersen ) have gone off into the hills . \r\n",
      "he takes her to a sacred site , even today strictly men-only . \r\n",
      "she appears to not know this . \r\n",
      "tony tells her that this is a special place , an initiation place . \r\n",
      "he then makes love to her , surrounded by ancient rock art . \r\n",
      "the community finds out about this sacrilegious act and it's payback time . \r\n",
      "the fuse is lit and the brittle inter-racial peace is shattered . \r\n",
      "everyone is affected in the fall out . \r\n",
      "to say more is to give away the details of this finely crafted film . \r\n",
      "suffice to say it's a rewarding experience . \r\n",
      "bryan brown , acting and co-producing , is the pivotal character . \r\n",
      "his officer is real , human and therefore flawed . \r\n",
      "brown comments that he expects audiences to feel warmth towards the man , then suddenly feel angry about him . \r\n",
      "it wasn't long ago that i visited central australia - ayers rock ( uluru ) and alice springs - for the first time . \r\n",
      "the wide-screen cinematography shows the dead heart of australia in a way that captures it's vicious beauty , but never deteriorates into a moving slide show , in which the gorgeous background dominates those pesky actors in the foreground . \r\n",
      "the cultural clash has provided the thesis for many a film ; from the western to the birdcage . \r\n",
      "at least three excellent australian films have covered the aboriginal people and the line between them and we anglo-saxon 'invaders' : \" jedda \" , \" the chant of jimmie blacksmith \" and \" the last wave \" . \r\n",
      "in a year when the race 'debate' has reared up in australia , it is nourishing to see such an intelligent , non-judgemental film as \" dead heart \" . \r\n",
      "the aboriginal priest best sums this up . \r\n",
      "he is asked to say if he is a \" black fella or white fella \" . \r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Positive review\n",
    "print(df['review'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7020ebbf",
   "metadata": {},
   "source": [
    "We aren't missing any labels buy we're missing a few reviews. We can safely drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c51c518b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "review    35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16cae688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a2d62ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     0\n",
       "review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acca23f1",
   "metadata": {},
   "source": [
    "Sometimes in the databases we don't have `null` values directly. Instead we can have a blank string. We want to detect and remove empty strings with `isspace()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af7f07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks = []\n",
    "\n",
    "for i, lb, rv in df.itertuples():\n",
    "    if rv.isspace():\n",
    "        blanks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c9082f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09d73656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1938, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2969cd",
   "metadata": {},
   "source": [
    "## Data Split\n",
    "\n",
    "Here we will split the data into the training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "309a21fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7f0ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f02f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a0ddd",
   "metadata": {},
   "source": [
    "## Pipeline building\n",
    "\n",
    "Let's build a pipeline to vectorize the data and then train and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15d0b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dfb98616",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), \n",
    "                     ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "39eef73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a1b6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae219ce",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "Let's evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "419a8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2183980d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[235  47]\n",
      " [ 41 259]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56bcca63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.83      0.84       282\n",
      "         pos       0.85      0.86      0.85       300\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       582\n",
      "   macro avg       0.85      0.85      0.85       582\n",
      "weighted avg       0.85      0.85      0.85       582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dca9b786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8487972508591065\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2278a4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
